{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - We extract the data from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yup i've finished c Ã¼ there...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remember to ask alex about his pizza</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No da..today also i forgot..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ola would get back to you maybe not today but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fwiw the reason I'm only around when it's time...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message Spam\n",
       "0                    Yup i've finished c Ã¼ there...    0\n",
       "1               Remember to ask alex about his pizza    0\n",
       "2                       No da..today also i forgot..    0\n",
       "3  Ola would get back to you maybe not today but ...    0\n",
       "4  Fwiw the reason I'm only around when it's time...    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_data(message_file):\n",
    "    # Create dataframe\n",
    "    data = pd.DataFrame(columns=['Message', 'Spam'])\n",
    "\n",
    "    # Open the file\n",
    "    with open(message_file, 'r') as file:\n",
    "        for line in file:\n",
    "            # Get spam boolean value and line string\n",
    "            if line.split()[0] == 'ham':\n",
    "                spam = 0\n",
    "                line = line[4:-1]\n",
    "            elif line.split()[0] == 'spam':\n",
    "                spam = 1\n",
    "                line = line[8:-1]\n",
    "            \n",
    "            # Append new row\n",
    "            data = data.append({ 'Message': line, 'Spam': spam }, ignore_index=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = extract_data('messages.txt')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Divide the data in training and test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 2)\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "def divide_data(data, train_frac=0.8):\n",
    "    # Divide\n",
    "    df_train = data.sample(frac=train_frac)\n",
    "    df_test = data.drop(df_train.index)\n",
    "    \n",
    "    # Reset indexes\n",
    "    df_train = df_train.reset_index()\n",
    "    df_train.drop(columns='index', inplace=True)\n",
    "    df_test = df_test.reset_index()\n",
    "    df_test.drop(columns='index', inplace=True)\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "df_train, df_test = divide_data(data)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Generate a dictionary from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('call', 273), ('get', 231), ('ur', 213), ('go', 168)]\n"
     ]
    }
   ],
   "source": [
    "def make_dictionary(df, nb_words=2000):\n",
    "    # We have a list of 'stop words': commonly used words that are useless for Spam identification \n",
    "    # (see https://www.geeksforgeeks.org/removing-stop-words-nltk-python/)\n",
    "    stop_words = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once',\n",
    "                  'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', \n",
    "                  'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', \n",
    "                  's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', \n",
    "                  'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', \n",
    "                  'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', \n",
    "                  'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', \n",
    "                  'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', \n",
    "                  'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', \n",
    "                  'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', \n",
    "                  'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', \n",
    "                  'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "    all_words = []\n",
    "    \n",
    "    # Read all the data\n",
    "    for i, row in df.iterrows():\n",
    "        # Add words\n",
    "        all_words += row['Message'].split()\n",
    "    \n",
    "    # Create dictionary\n",
    "    dictionary = Counter(all_words)\n",
    "    \n",
    "    # Remove bad items\n",
    "    for item in list(dictionary):\n",
    "        # Non-alphanumeric words\n",
    "        if item.isalpha() == False:\n",
    "            del dictionary[item]\n",
    "        # One letter words\n",
    "        elif len(item) == 1:\n",
    "            del dictionary[item]\n",
    "        # Elimate bad words for Spam identification\n",
    "        elif item.lower() in stop_words:\n",
    "            del dictionary[item]\n",
    "    \n",
    "    # Keep the *nb_words* most common words\n",
    "    dictionary = dictionary.most_common(nb_words)\n",
    "    \n",
    "    return dictionary\n",
    "              \n",
    "dictionary = make_dictionary(df_train, nb_words=1500)\n",
    "print(dictionary[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Extract features from the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>call</th>\n",
       "      <th>get</th>\n",
       "      <th>ur</th>\n",
       "      <th>go</th>\n",
       "      <th>know</th>\n",
       "      <th>like</th>\n",
       "      <th>got</th>\n",
       "      <th>come</th>\n",
       "      <th>want</th>\n",
       "      <th>...</th>\n",
       "      <th>returns</th>\n",
       "      <th>however</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>insurance</th>\n",
       "      <th>Msgs</th>\n",
       "      <th>gentle</th>\n",
       "      <th>juicy</th>\n",
       "      <th>Convey</th>\n",
       "      <th>hip</th>\n",
       "      <th>kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Spam  call  get  ur  go  know  like  got  come  want ...  returns  however  \\\n",
       "0    0     0    0   1   0     0     0    1     0     0 ...        0        0   \n",
       "1    0     0    0   0   0     0     0    0     0     0 ...        0        0   \n",
       "2    0     0    0   0   0     0     0    0     0     0 ...        0        0   \n",
       "3    0     0    0   0   0     0     0    0     0     0 ...        0        0   \n",
       "4    0     0    0   0   0     0     0    0     0     0 ...        0        0   \n",
       "\n",
       "   Chinese  insurance  Msgs  gentle  juicy  Convey  hip  kb  \n",
       "0        0          0     0       0      0       0    0   0  \n",
       "1        0          0     0       0      0       0    0   0  \n",
       "2        0          0     0       0      0       0    0   0  \n",
       "3        0          0     0       0      0       0    0   0  \n",
       "4        0          0     0       0      0       0    0   0  \n",
       "\n",
       "[5 rows x 1501 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features(df, dictionary, multi=True):\n",
    "    # Add feature columns to dataframe\n",
    "    for word_id, d in enumerate(dictionary):\n",
    "        df[d[0]] = 0\n",
    "    \n",
    "    # Read all rows\n",
    "    for row_id, row in df.iterrows():\n",
    "        # Get all the words of the message\n",
    "        word_list = row['Message'].split()\n",
    "        \n",
    "        # For all these words\n",
    "        for word in word_list:\n",
    "            # For all the words in the dictionary\n",
    "            for word_id, d in enumerate(dictionary):\n",
    "                if (d[0] == word) and (row[d[0]] == 0):\n",
    "                    if multi:\n",
    "                        # Put the count of this word in the right columns\n",
    "                        df.at[row_id, d[0]] = word_list.count(word)\n",
    "                    else:\n",
    "                        # Put 1 in the right column\n",
    "                        df.at[row_id, d[0]] = 1\n",
    "    \n",
    "    # Remove 'Message' column\n",
    "    df.drop(columns='Message', inplace=True)\n",
    "\n",
    "extract_features(df_train, dictionary)\n",
    "extract_features(df_test, dictionary)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Implement the fit function of the Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(df):\n",
    "    # theta_n | y = 0 AND theta_n | y = 1\n",
    "    theta_n = [pd.Series(), pd.Series()]\n",
    "    theta_y = 0\n",
    "    I = df.shape[0]\n",
    "                    \n",
    "    # Get the nb of spams\n",
    "    nb_spam = df['Spam'].sum()\n",
    "    \n",
    "    # Get the nb of hams\n",
    "    nb_ham = I - nb_spam\n",
    "    \n",
    "    # Compute theta_y\n",
    "    theta_y = nb_spam / I\n",
    "    \n",
    "    # For all words\n",
    "    for word in df.drop(columns='Spam').columns:\n",
    "        theta_n[1][word] = ((df['Spam'] * df[word]).sum() + 1) / (nb_spam + 2)\n",
    "        theta_n[0][word] = (((1 - df['Spam']) * df[word]).sum() + 1) / (nb_ham + 2)\n",
    "        \n",
    "    return theta_n, theta_y\n",
    "\n",
    "theta_n, theta_y = fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Implement the predict function of the Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta_n, theta_y):\n",
    "    X['Prediction'] = 0\n",
    "    \n",
    "    # For all rows\n",
    "    for row_id, row in X.drop(columns='Prediction').iterrows():\n",
    "        # Compute the probability of each word\n",
    "        prob_0 = row * theta_n[0]\n",
    "        prob_1 = row * theta_n[1]\n",
    "        \n",
    "        # Compute the probability of P(Y|X)\n",
    "        predict_0 = (1 - theta_y)\n",
    "        predict_1 = theta_y\n",
    "        for prob in prob_0:\n",
    "            if prob != 0:\n",
    "                predict_0 *= prob\n",
    "        for prob in prob_1:\n",
    "            if prob != 0:\n",
    "                predict_1 *= prob\n",
    "        \n",
    "        # Conclude with prediction: whatever is the highest prediction\n",
    "        if predict_1 >= predict_0:\n",
    "            X.at[row_id, 'Prediction'] = 1\n",
    "    \n",
    "    return X['Prediction']\n",
    "\n",
    "prediction = predict(df_test.drop(columns='Spam'), theta_n, theta_y)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 - Compute the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spam</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>791</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction    0    1\n",
       "Spam                \n",
       "0           791   63\n",
       "1             8  138"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = pd.crosstab(df_test['Spam'], prediction)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have good results. The accuracy is 92.9%, which is pretty good. However, we have a lot of False positives.\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100 * (conf_mat[0][0] + conf_mat[1][1]) / conf_mat.sum().sum()\n",
    "print('We have good results. The accuracy is {}%, which is pretty good. However, we have a lot of False positives.'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
